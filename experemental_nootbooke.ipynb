{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from  pathlib import Path\n",
    "import calendar\n",
    "import datetime\n",
    "import pickle\n",
    "#import py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_category = ['Hair Conditioners',\n",
    " 'Laundry Detergents',\n",
    " 'MALE B&R',\n",
    " 'Shampoos',\n",
    " 'Feminine Care',\n",
    " 'Diapers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(name_of_file):\n",
    "    cat_dict = {'br': 'MALE B&R',\n",
    " 'deterg': 'Laundry Detergents',\n",
    " 'diapers': 'Diapers',\n",
    " 'femcare': 'Feminine Care',\n",
    " 'haircond': 'Hair Conditioners',\n",
    " 'shampoo': 'Shampoos',\n",
    " 'MALE B&R': 'MALE B&R',\n",
    " 'Laundry Detergents': 'Laundry Detergents',\n",
    " 'Diapers': 'Diapers',\n",
    " 'Feminine Care': 'Feminine Care',\n",
    " 'Hair Conditioners': 'Hair Conditioners',\n",
    " 'Shampoos': 'Shampoos'}\n",
    "    for k in cat_dict.keys():\n",
    "        if name_of_file.count(k):\n",
    "            return cat_dict[k]\n",
    "    else:\n",
    "        raise ValueError('В названии файла нет категории', name_of_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'py7zr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m         zip_file\u001b[38;5;241m.\u001b[39mextractall(tmp_zip)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m z \u001b[38;5;129;01min\u001b[39;00m z_files:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpy7zr\u001b[49m\u001b[38;5;241m.\u001b[39mSevenZipFile(z, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m archive:\n\u001b[0;32m     16\u001b[0m         archive\u001b[38;5;241m.\u001b[39mexctractall(tmp_7z)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m list_of_category:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'py7zr' is not defined"
     ]
    }
   ],
   "source": [
    "paths = Path('data/new_format_data')\n",
    "\n",
    "zip_files = list(paths.glob('*.zip')) \n",
    "tmp_zip = Path('./data/tmp/zip').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "z_files = list(paths.glob('*.7z'))\n",
    "tmp_7z = Path('./data/tmp/7z').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "for zip_f in zip_files:\n",
    "    with ZipFile(zip_f) as zip_file: \n",
    "        zip_file.extractall(tmp_zip)\n",
    "\n",
    "for z in z_files:\n",
    "    with py7zr.SevenZipFile(z, 'r') as archive:\n",
    "        archive.exctractall(tmp_7z)\n",
    "\n",
    "\n",
    "for cat in list_of_category:\n",
    "            df_check = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path('./data/tmp/in').rglob('*.parquet') )\n",
    "categories = list([get_category(name.name) for name in files])\n",
    "file_df = pd.DataFrame(files,categories).reset_index()\n",
    "file_df.columns = ['category', 'file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('demo', 'Diapers_axsm_pg_diapers_product_2021-10-01_12.parquet')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0].parts[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in  file_df['category'].unique():\n",
    "    print(c)\n",
    "    names = file_df[file_df['category']==c]['file'].values\n",
    "    categry_df = pd.DataFrame()\n",
    "    progress_bar = tqdm(names)\n",
    "    for f in progress_bar:\n",
    "        progress_bar.set_postfix({'name_of_file': f})\n",
    "        tmp_df = pd.read_parquet(f) \n",
    "        tmp_df['file'] = '/'.join(f.parts[-2:])\n",
    "        categry_df = pd.concat([categry_df,tmp_df ], ignore_index= True )\n",
    "        \n",
    "    categry_df.to_parquet(f'data/tmp/{c}.pq', index=False)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pampers = pd.read_parquet(r\"C:\\Users\\nyzhur\\git\\DT-PG-NZ\\data\\tmp\\Diapers.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "legends = pd.read_excel(r'.\\codes\\Example.xlsx', sheet_name = 'legends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_pampers = pd.read_parquet(r\"C:\\Users\\nyzhur\\git\\DT-PG-NZ\\data\\tmp\\промежуточное\\Diapers.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_group = pd.read_excel(r'.\\codes\\feature_groups.xlsx')\n",
    "demo_order = pd.read_excel(r'.\\codes\\demo_order.xlsx')\n",
    "demo_order['buyers_gr_label'] = demo_order['buyers_gr_label'].astype(str).str.lower()\n",
    "periods = pd.read_excel(r'.\\codes\\periods.xlsx', sheet_name ='period_lbl')\n",
    "time_period_type = pd.read_excel(r'.\\codes\\periods.xlsx', sheet_name ='time_period_type')\n",
    "year = pd.read_excel(r'.\\codes\\periods.xlsx', sheet_name ='year')\n",
    "segments_order = pd.read_excel(r'.\\codes\\segments_order.xlsx')\n",
    "example = pd.read_excel(r'.\\codes\\Example.xlsx', sheet_name = 'example')\n",
    "legends = pd.read_excel(r'.\\codes\\Example.xlsx', sheet_name = 'legends')\n",
    "shop_order = pd.read_excel(r'.\\codes\\shop_order.xlsx')\n",
    "today = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "#get_low!\n",
    "list_of_dict = [features_group,demo_order, periods,time_period_type,year,\\\n",
    "                 segments_order,example,legends,shop_order]\n",
    "for d in list_of_dict:\n",
    "    d.columns = [c.lower() for c in d.columns ]\n",
    "\n",
    "fin_cols = example.columns.to_list() + ['shop_code', 'shop_lvls','channel_code', 'file']\n",
    "columns_dict = legends[['mask','Colum'.lower()]].dropna(subset='mask').set_index('mask').to_dict()['Colum'.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_lbl(time_period_type, year, month):\n",
    "    return f\"{time_period_type.split('/')[0]}: {calendar.month_abbr[month]} {year}\"\n",
    "\n",
    "def get_label_num(time_period_type, year, month):\n",
    "    return f\"{time_period_type.split('/')[0]}: {year} ({str(month).zfill(2)}) {calendar.month_abbr[month]}\"\n",
    "\n",
    "\n",
    "\n",
    "def add_period_lbls(df_in, periods,time_period_type):\n",
    "\n",
    "\n",
    "    time_period_type_dict = {24 :'2MATs/ 104 we', 12:'MAT/ 52 we', 3:'3MMT/ 12we', 1: 'Month'}\n",
    "    \n",
    "    col_to_int = ['duration', 'year', 'month']\n",
    "    df_in[col_to_int] = df_in[col_to_int].astype(int)\n",
    "    \n",
    "    df_in['time_period_type'] = df_in['duration'].map(time_period_type_dict)\n",
    "    \n",
    "    df_tmp_per = df_in[['time_period_type', 'year', 'month']].drop_duplicates()\n",
    "    df_tmp_per['period_lbl'] = df_tmp_per[['time_period_type', 'year', 'month']]\\\n",
    "        .apply(lambda row: get_period_lbl(*row), axis=1)\n",
    "    \n",
    "    df_tmp_per['label_num'] = df_tmp_per[['time_period_type', 'year', 'month']]\\\n",
    "        .apply(lambda row: get_label_num(*row), axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    new_periods = set(df_tmp_per['period_lbl']) - set(periods['period_lbl'])\n",
    "    if len(new_periods):\n",
    "        print('New periods!')\n",
    "        print(*new_periods)\n",
    "        new_periods_df = df_tmp_per[df_tmp_per['period_lbl'].isin(new_periods)].sort_values(by=['year','month'])\n",
    "        new_periods_df['date_added'] = today\n",
    "        periods = pd.concat([periods[['period_lbl','label_num','date_added' ]], new_periods_df[['period_lbl','label_num','date_added' ]]],ignore_index=True )\n",
    "        periods['period_code'] = range(1,len(periods)+1)\n",
    "\n",
    "\n",
    "        with pd.ExcelWriter(r'.\\codes\\periods.xlsx',engine=\"openpyxl\",mode=\"a\", if_sheet_exists='replace') as writer:\n",
    "            periods.to_excel(writer, sheet_name ='period_lbl')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_in = df_in.merge(df_tmp_per,on = ['time_period_type', 'year', 'month'], how='left')\n",
    "    \n",
    "    df_in = df_in.merge(\n",
    "            periods, on=['period_lbl', 'label_num'],  how='left', validate='many_to_one')\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_in = df_in.merge(\n",
    "           time_period_type, on='time_period_type', how='left', validate='many_to_one')\n",
    "\n",
    "    df_in = df_in.drop(columns=['time_period_type', 'period_lbl', 'month' ])\\\n",
    "            .rename(columns={'time_period_code': 'time_period_type', 'period_code': 'period_lbl'})\n",
    "\n",
    "    return df_in\n",
    "\n",
    "def get_df_in_v2(df_in, category, columns_dict, features_group):\n",
    "    \n",
    "    #get_low_2!\n",
    "    df_in.columns = [c.lower() for c in df_in.columns]\n",
    "\n",
    "\n",
    "    df_in = df_in.rename(\n",
    "        {'Category Name'.lower():'Product Name'.lower(), 'Buyer Group Name'.lower():'buyers_gr_label'}, \n",
    "        axis=1)\n",
    "    df_in['Category Name'.lower()] = category\n",
    "    df_in['buyers_gr_label'] = df_in['buyers_gr_label'].replace({'Total Population' :'TOTAL DEMOGRAPHICS'})\n",
    "    df_in = df_in.drop('category',axis=1)\n",
    "\n",
    "\n",
    "    #print('init shape', df_in.shape)\n",
    "\n",
    "\n",
    "        \n",
    "    # products\n",
    "    prod_col_to_merge = 'Product Name'.lower()\n",
    "    if  len(set(df_in['Product Name'.lower()].unique()) - set(features_group['Product Name'.lower()]))>0:\n",
    "        print('Мерджим по фулл нейму')\n",
    "        prod_col_to_merge = 'full_label'\n",
    "        features_group = features_group.drop(columns='Product Name'.lower())\n",
    "\n",
    "    \n",
    "    df_in = df_in.merge(\n",
    "        features_group, \n",
    "        left_on=['Category Name'.lower(), 'Product Name'.lower()], \n",
    "        right_on=['Category Name'.lower(),  prod_col_to_merge], \n",
    "        how='left', validate='many_to_one') #Есть множественные ключи в features_group['Product Name']\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_in = df_in.rename(\n",
    "        columns={'product_code': 'products', 'category_code': 'category', 'feature_code': 'features'}\n",
    "    )\n",
    "    df_in['product_hier'] = df_in['products']\n",
    "\n",
    "\n",
    "    # socdem\n",
    "    df_in['buyers_gr_label'] = df_in['buyers_gr_label'].str.lower()\n",
    "    df_in = df_in.merge(\n",
    "        demo_order, on=['buyers_gr_label'], how='left', validate='many_to_one')\n",
    "    df_in = df_in.rename(columns={'demo_code': 'demo_groups'})\n",
    "    df_in['demo_hier'] = df_in['demo_groups']\n",
    "\n",
    "    \n",
    "    # segments\n",
    "\n",
    "    if ('Segment'.lower() not in df_in.columns):\n",
    "        if (category == 'Feminine Care'):\n",
    "            df_in['Segment'.lower()] = 'Total Feminine Care'\n",
    "        elif (category == 'Shampoos'):\n",
    "            df_in['Segment'.lower()] = 'Shampoos'\n",
    "    \n",
    "\n",
    "    \n",
    "    if (category == 'Laundry Detergents'):\n",
    "        df_in['Segment'.lower()] = df_in['Segment'.lower()].replace(\n",
    "            {'Total Detergents excluding Bars': 'Total Detergents excluding Bar'})\n",
    "    df_in['Segment'.lower()] =df_in['Segment'.lower()].replace({'Total Diapers size':'Total Diapers'})\n",
    "    df_in = df_in.merge(\n",
    "        segments_order, on=['Segment'.lower()], how='left', validate='many_to_one')\n",
    "    df_in = df_in.rename(columns={'segment_code': 'cat_segment'})\n",
    "\n",
    "\n",
    "    # shop\n",
    "    df_in['position_name_shop'] = df_in['position_name_shop'].replace(\n",
    "    {'Ok Hyper': 'OK Hyper', 'Perekryostok': 'Perekrestok'})\n",
    "    df_in = df_in.merge(\n",
    "        shop_order, on=['position_name_shop'], how='left', validate='many_to_one')\n",
    "\n",
    "    \n",
    "    #print('merged shape', df_in.shape)\n",
    "    \n",
    "    # rename metrics\n",
    "    df_in.columns = [col.lower().replace(' ','_') for col in df_in.columns]\n",
    "    df_in = df_in.rename(columns_dict, axis=1)\n",
    "\n",
    "    \n",
    "    return df_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hellen Harper Soft&Dry Non-Taped',\n",
       " 'Pampers T2 Non-Taped Total Total',\n",
       " 'Retailer brand 365 Dney Non-Taped',\n",
       " 'Retailer brand Baby Go Non-Taped'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(clear_pampers['Category Name'.lower()].unique()) - set(features_group['Product Name'.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(clear_pampers['Category Name'.lower()].unique()) - set(features_group['full_label'.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Мерджим по фулл нейму\n"
     ]
    }
   ],
   "source": [
    "res = get_df_in_v2(clear_pampers, 'Diapers', columns_dict, features_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>segment</th>\n",
       "      <th>buyers_gr_label</th>\n",
       "      <th>position_name_shop</th>\n",
       "      <th>spend_local_currency</th>\n",
       "      <th>volume_gl</th>\n",
       "      <th>volume_physical_units</th>\n",
       "      <th>volume_su</th>\n",
       "      <th>trips_raw</th>\n",
       "      <th>occasions</th>\n",
       "      <th>...</th>\n",
       "      <th>demo_lvls</th>\n",
       "      <th>socdem_gr</th>\n",
       "      <th>cat_segment</th>\n",
       "      <th>shop_code</th>\n",
       "      <th>hier</th>\n",
       "      <th>shop_lvls</th>\n",
       "      <th>shop_hier</th>\n",
       "      <th>channel_type</th>\n",
       "      <th>channel_code</th>\n",
       "      <th>shop_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Diapers</td>\n",
       "      <td>Total Diapers</td>\n",
       "      <td>total demographics</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "      <td>4.812561e+07</td>\n",
       "      <td>2624.097997</td>\n",
       "      <td>14578.438644</td>\n",
       "      <td>57000.820444</td>\n",
       "      <td>12878.0</td>\n",
       "      <td>43715.265072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0 RUSSIA NATIONAL</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Diapers</td>\n",
       "      <td>Total Diapers</td>\n",
       "      <td>size of households</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "      <td>4.812561e+07</td>\n",
       "      <td>2624.097997</td>\n",
       "      <td>14578.438644</td>\n",
       "      <td>57000.820444</td>\n",
       "      <td>12878.0</td>\n",
       "      <td>43715.265072</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0 RUSSIA NATIONAL</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Diapers</td>\n",
       "      <td>Total Diapers</td>\n",
       "      <td>1</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "      <td>1.828382e+06</td>\n",
       "      <td>96.941043</td>\n",
       "      <td>538.565648</td>\n",
       "      <td>2425.211514</td>\n",
       "      <td>571.0</td>\n",
       "      <td>1984.690582</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0 RUSSIA NATIONAL</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diapers</td>\n",
       "      <td>Total Diapers</td>\n",
       "      <td>2</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "      <td>4.277845e+06</td>\n",
       "      <td>239.037002</td>\n",
       "      <td>1327.993951</td>\n",
       "      <td>5096.243527</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>3783.258468</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0 RUSSIA NATIONAL</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diapers</td>\n",
       "      <td>Total Diapers</td>\n",
       "      <td>3</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "      <td>1.424264e+07</td>\n",
       "      <td>734.939132</td>\n",
       "      <td>4083.027791</td>\n",
       "      <td>14500.245537</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>11058.175486</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0.0 RUSSIA NATIONAL</td>\n",
       "      <td>Total</td>\n",
       "      <td>1</td>\n",
       "      <td>RUSSIA NATIONAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_name        segment     buyers_gr_label position_name_shop  \\\n",
       "0      Diapers  Total Diapers  total demographics    RUSSIA NATIONAL   \n",
       "1      Diapers  Total Diapers  size of households    RUSSIA NATIONAL   \n",
       "2      Diapers  Total Diapers                   1    RUSSIA NATIONAL   \n",
       "3      Diapers  Total Diapers                   2    RUSSIA NATIONAL   \n",
       "4      Diapers  Total Diapers                   3    RUSSIA NATIONAL   \n",
       "\n",
       "   spend_local_currency    volume_gl  volume_physical_units     volume_su  \\\n",
       "0          4.812561e+07  2624.097997           14578.438644  57000.820444   \n",
       "1          4.812561e+07  2624.097997           14578.438644  57000.820444   \n",
       "2          1.828382e+06    96.941043             538.565648   2425.211514   \n",
       "3          4.277845e+06   239.037002            1327.993951   5096.243527   \n",
       "4          1.424264e+07   734.939132            4083.027791  14500.245537   \n",
       "\n",
       "   trips_raw     occasions  ...  demo_lvls  socdem_gr  cat_segment  shop_code  \\\n",
       "0    12878.0  43715.265072  ...        0.0        1.0          100          1   \n",
       "1    12878.0  43715.265072  ...        1.0        8.0          100          1   \n",
       "2      571.0   1984.690582  ...        2.0        8.0          100          1   \n",
       "3     1024.0   3783.258468  ...        2.0        8.0          100          1   \n",
       "4     3449.0  11058.175486  ...        2.0        8.0          100          1   \n",
       "\n",
       "    hier  shop_lvls              shop_hier  channel_type  channel_code  \\\n",
       "0  1.0.0          1  1.0.0 RUSSIA NATIONAL         Total             1   \n",
       "1  1.0.0          1  1.0.0 RUSSIA NATIONAL         Total             1   \n",
       "2  1.0.0          1  1.0.0 RUSSIA NATIONAL         Total             1   \n",
       "3  1.0.0          1  1.0.0 RUSSIA NATIONAL         Total             1   \n",
       "4  1.0.0          1  1.0.0 RUSSIA NATIONAL         Total             1   \n",
       "\n",
       "         shop_name  \n",
       "0  RUSSIA NATIONAL  \n",
       "1  RUSSIA NATIONAL  \n",
       "2  RUSSIA NATIONAL  \n",
       "3  RUSSIA NATIONAL  \n",
       "4  RUSSIA NATIONAL  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING\n",
      " columns with na:\n",
      "buyer_group_id    114604\n",
      "demo_groups       114604\n",
      "demo_hier         114604\n",
      "demo_lvls         114604\n",
      "socdem_gr         114604\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "chk_na = res.isna().sum()    \n",
    "if chk_na[chk_na > 0].shape[0] > 0:\n",
    "        print('WARNING\\n', 'columns with na:')\n",
    "        print(chk_na[chk_na > 0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['young singles/couples without children (<35 years)',\n",
       "       'mature singles/couples without children (35-49 years)',\n",
       "       'senior singles/couples without children (50-64 years)',\n",
       "       'retired singles/couples without children (>65 years)',\n",
       "       'family with children 6-12 years',\n",
       "       'family with children 13-18 years'], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[res['buyer_group_id'].isna()]['buyers_gr_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1842068    shops/Diapers_axsm_pg_diapers_product_2024-09-...\n",
       "1842069    shops/Diapers_axsm_pg_diapers_product_2024-09-...\n",
       "1842070    shops/Diapers_axsm_pg_diapers_product_2024-09-...\n",
       "1842071    shops/Diapers_axsm_pg_diapers_product_2024-09-...\n",
       "1842072    shops/Diapers_axsm_pg_diapers_product_2024-09-...\n",
       "Name: file, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['file'].tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
